import math
import random
from abc import ABC

import numpy as np
import pyglet
from gym.envs.classic_control import rendering
from gym.spaces import flatten, flatdim
from gym.vector.utils import spaces

from environments.environment import Environment
from environments.fishTank.character import Character
from environments.fishTank.health import Health
from environments.fishTank.mapGenerator import generate_map
from environments.fishTank.wall import Wall
from modules.collisions.collisions import solve_collisions
from modules.raymarch.ray import ray_march
from modules.renderingTools import Texture
from modules.utils.mathHelper import angle_to_vector, get_velocity
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap

WINDOW_W = 500
WINDOW_H = 500


class FishTank(Environment, ABC):
    """
    A 2d procedurally generated fish tank containing food pellets and a physics simulation driven using Verlet
    integration. Each character in the environment receives a sequence of observations generated by casting rays out
    from the character's head. This 1D RGB image is flattened into a single array, and appended with the character's
    current actions, their body position as a percentage of the tank size in the x and y dimension, their direction in
    terms of normalised x and y coordinates, and their velocity is normalised by their maximum acceleration.

    The controller then processes the input and returns an array of outputs Actions correspond to
    [forward_thrust (0 - 1),
    rotational acceleration (0 full counter-clockwise, 0.5 - still, 1 - full clockwise]
    """
    metadata = {'render.modes': ['human']}
    reset_interval = 5000
    obs_pixels = 80

    def __init__(self):
        super().__init__("FishTank-v0")
        self.grid = None
        self.viewer = None

        self.x_size = 400
        self.y_size = 300

        self.action_space = spaces.Box(low=-1, high=1, shape=(2,))
        self.observation_space = spaces.OrderedDict({
            "vision": spaces.Box(low=0, high=1, shape=(self.obs_pixels * 3,)),
            "dynamics": spaces.OrderedDict({
                "collision_force": spaces.Box(low=-np.inf, high=np.inf, shape=(1,)),
                "position": spaces.Box(low=0, high=1, shape=(2,)),
                "direction": spaces.Box(low=0, high=1, shape=(2,)),
                "velocity": spaces.Box(low=0, high=1, shape=(1,)),
            })
        })
        self.time = 1
        self.maxHealth = 8
        self.healthItems = []
        self.character = Character(self.x_size / 2, self.y_size / 2, obs_pixels=FishTank.obs_pixels)
        self.reset()

    def step(self, actions: list):
        if self.time % FishTank.reset_interval == 0 and FishTank.reset_interval != -1:
            self.reset()

        # perform character simulation
        self.character.step(self, actions)
        solve_collisions(self.grid, self.character)

        # Compute reward
        reward = 0

        # Add reward for colliding with health
        for health in self.healthItems:
            dist = math.sqrt((health.x - self.character.body[0].x) ** 2 + (health.y - self.character.body[0].y) ** 2)
            if dist < self.character.size + health.size:
                self.healthItems.remove(health)
                reward += health.size * 100
                self.spawn_health()

        # Penalise collisions
        if self.character.collision_force > 0.05:
            reward -= 0.5 + self.character.collision_force * 3

        # Add reward for going faster (assuming forward thrust > 0 so reversing isn't penalised)
        velocity = get_velocity(self.character.body[0]) / self.character.maxAccel
        if actions is not None and actions[0] > 0:
            reward += velocity * 0.2

        self.time += 1

        observation = {
            "vision": self.get_observation(self.character),
            "dynamics": {
                "collision_force": [self.character.collision_force],
                "position": [self.character.body[0].x / self.x_size, self.character.body[0].y / self.y_size],
                "direction": angle_to_vector(self.character.dir),
                "velocity": [velocity],
            }
        }

        return observation, reward

    def random_policy(self):
        return self.character.random_policy()

    def reset(self):
        # Reset the state of the environment to an initial state
        self.grid = generate_map([self.x_size, self.y_size], round(self.x_size / 20), 0.6, 0.2)
        self.character.reset(self)
        self.healthItems = []
        self.time = round(self.time/self.reset_interval) * self.reset_interval
        while len(self.healthItems) < self.maxHealth:
            self.spawn_health()

    def close(self):
        if self.viewer:
            self.viewer.close()
            self.viewer = None

    def render(self, agent, mode='human', close=False):
        from modules.controller.agentController import AgentController

        info_str = f"Time: {self.time}"

        if self.viewer is None:
            self.viewer = rendering.Viewer(WINDOW_W, WINDOW_H)
            bg = rendering.FilledPolygon([(0, 0), (0, WINDOW_H), (WINDOW_W, WINDOW_H), (WINDOW_W, 0)])
            bg.set_color(0, 0, 0)
            border = rendering.PolyLine([(0, 0), (0, self.y_size), (self.x_size, self.y_size), (self.x_size, 0)],
                                        close=True)
            border.set_linewidth(5)
            border.set_color(*Wall.colour)

            self.viewer.add_geom(bg)
            self.viewer.add_geom(border)
            self.viewer.transform = rendering.Transform()

        scale = max(WINDOW_W / self.x_size, WINDOW_H / self.x_size)
        self.viewer.transform.set_scale(scale, scale)

        for x in range(len(self.grid)):
            for y in range(len(self.grid[0])):
                if self.grid[x][y]:
                    Wall.render(self.viewer, x, y, 20)

        # Draw health
        for health in self.healthItems:
            health.render(self.viewer)

        # Draw bot
        self.character.render(self.viewer)

        # Draw output view
        obs_shape = (self.obs_pixels, 3)
        vision_size = flatdim(self.observation_space["vision"])
        o = np.reshape(agent.observations[-1, :vision_size], obs_shape)
        r = np.reshape(agent.reconstructions[-1], obs_shape)
        p = np.reshape(agent.predictions[-2, :vision_size], obs_shape)

        self.draw_observation(o, self.x_size - 180, self.y_size + 80, 180, 20, colour=(50, 50, 50))

        if isinstance(agent, AgentController):
            self.draw_observation(r, self.x_size - 180, self.y_size + 60, 180, 20, colour=(50, 50, 50))
            self.draw_observation(p, self.x_size - 180, self.y_size + 40, 180, 20, colour=(50, 50, 50))
            self.draw_neural_map(agent.network_vis, self.x_size - 260, self.y_size, 100, 100, colour=(50, 50, 50))

            start_x = 250
            start_y = self.y_size + 40
            speed = math.sqrt((self.character.body[0].x - self.character.body[0].prev_x) ** 2 +
                              (self.character.body[0].y - self.character.body[0].prev_y) ** 2)
            end_x = start_x + math.cos(self.character.dir) * speed * 5
            end_y = start_y + math.sin(self.character.dir) * speed * 5
            line = self.viewer.draw_line((start_x, start_y), (end_x, end_y), linewidth=3)
            line.set_color(255, 0.0, 0.0, 1)

            # Add info to string

            info_str += f"\nReconstr_loss: {agent.reconstruction_loss:.3f}"
            info_str += f"\nPred_loss: {agent.prediction_loss:.3f}"
            info_str += f"\nReward: {agent.rewards[-1]:.3f}"
            info_str += f"\nQ_value: {agent.q_value:.3f}"
            info_str += f"\nActions: [{agent.actions[-1][0]:.3f}, {agent.actions[-1][1]:.3f}]"

        label = pyglet.text.Label(info_str, font_size=10,
                                  multiline=True,
                                  font_name="Russo One",
                                  width=200,
                                  x=0, y=WINDOW_H, anchor_x='left', anchor_y='top',
                                  color=(255, 255, 255, 255))
        self.viewer.add_label(label)

        return self.viewer.render()

    def spawn_health(self):
        if len(self.healthItems) >= self.maxHealth:
            return
        x, y = self.get_random_pos()
        health = Health(x, y)
        self.healthItems.append(health)

    def get_random_pos(self):
        valid_pos = False
        x, y = 0, 0
        while not valid_pos:
            x = random.randrange(0, self.x_size)
            y = random.randrange(0, self.y_size)
            valid_pos = not self.grid[math.floor(x / 20)][math.floor(y / 20)]
        return x, y

    def draw_observation(self, observation, x, y, w, h, colour=(100, 100, 255)):
        observation = np.repeat(observation[:, np.newaxis, :], 5, axis=1)
        observation = np.flip(np.swapaxes(observation, 0, 1), 1)
        observation = np.ascontiguousarray(observation, dtype=np.float32)

        tex = Texture(observation, x, y, w, h)
        self.viewer.add_onetime(tex)

        quad = rendering.PolyLine([(x, y), (x, y + h), (x + w, y + h), (x + w, y)], True)
        quad.set_color(*colour)
        quad.set_linewidth(1)
        self.viewer.add_onetime(quad)

    def draw_neural_map(self, map, x, y, w, h, colour=(100, 100, 255)):
        colors = [(1, 0.3333, 0), (0, 0, 0), (0.4157, 1, 0.2196)]  # Red, Black, Green
        cmap = LinearSegmentedColormap.from_list('custom_colormap', colors, N=256)

        map = np.flip(np.swapaxes(map, 0, 1), 1)
        map = cmap(map)[:, :, :3]
        map = np.ascontiguousarray(map, dtype=np.float32)

        tex = Texture(map, x, y, w, h)
        self.viewer.add_onetime(tex)

        quad = rendering.PolyLine([(x, y), (x, y + h), (x + w, y + h), (x + w, y)], True)
        quad.set_color(*colour)
        quad.set_linewidth(1)
        self.viewer.add_onetime(quad)

    def get_observation(self, character):
        observation = np.zeros((character.fidelity, 3), dtype=np.float32)
        ray_data = ray_march(character, self.grid, self.healthItems)

        # Create masks for each object type
        wall_mask = ray_data[:, 0] == 1
        health_mask = ray_data[:, 0] == 2

        # Update observation array based on object types
        observation[wall_mask, :3] = np.array(Wall.colour[:3]) / 255 * (
                1 - ray_data[wall_mask, 1][:, np.newaxis] / self.x_size)
        observation[health_mask, :3] = np.array(Health.colour[:3]) / 255 * (
                1 - ray_data[health_mask, 1][:, np.newaxis] / self.x_size)

        noise = np.random.normal(0, 1, observation.shape)
        observation += noise * 0.005
        return observation
